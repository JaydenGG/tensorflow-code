{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TENSORFLOW EXAMPLE: RECURRENT NEURAL NETWORK\n",
    "\n",
    "Problem: Adding two 8-bit numbers together.\n",
    "For example\n",
    "     00001001 + 00111100 = 01000101\n",
    "        9     +    60    = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the dataflow graph\n",
    "time_steps = 8        # time steps which is the same as the length of the bit-string\n",
    "input_dim = 2         # number of units in the input layer\n",
    "hidden_dim = 16       # number of units in the hidden layer\n",
    "output_dim = 1        # number of units in the output layer\n",
    "\n",
    "# input X and target ouput Y\n",
    "X = tf.placeholder(tf.float32, [None, time_steps, input_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, time_steps])\n",
    "\n",
    "# define the RNN cell: can be simple cell, LSTM or GRU\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(num_units=hidden_dim, activation=tf.nn.sigmoid)\n",
    "# cell = tf.nn.rnn_cell.LSTMCell(hidden_dim, state_is_tuple=True)\n",
    "\n",
    "# values is a tensor of shape [batch_size, time_steps, hidden_dim]\n",
    "# last_state is a tensor of shape [batch_size, hidden_dim]\n",
    "values, last_state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "values = tf.reshape(values,[time_steps, hidden_dim])\n",
    "\n",
    "# put the values from the RNN through fully-connected layer\n",
    "W = tf.Variable(tf.random_uniform([hidden_dim, output_dim], minval=-1.0,maxval=1.0), name='W')\n",
    "b = tf.Variable(tf.zeros([1, output_dim]), name='b')\n",
    "h = tf.nn.sigmoid(tf.matmul(values,W) + b)\n",
    "\n",
    "# minimize loss, using ADAM as weight update rule\n",
    "h_ = tf.reshape(h, [time_steps])\n",
    "Y_ = tf.reshape(Y, [time_steps])\n",
    "loss = tf.reduce_sum(-Y_ * tf.log(h_) - (1-Y_) * tf.log(1-h_))\n",
    "train_step = tf.train.AdamOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output values:\n",
      "[[ 0.47502092  0.47502097  0.52497905  0.47502092  0.52497905  0.52497888\n",
      "   0.47502086  0.47502092  0.52497894  0.47502086  0.47502086  0.524979\n",
      "   0.52497888  0.52497905  0.52497751  0.52497911]\n",
      " [ 0.14841537  0.61733449  0.75091577  0.28058618  0.56417257  0.68358868\n",
      "   0.16095461  0.29389748  0.40222776  0.20322989  0.34588733  0.72239882\n",
      "   0.79938602  0.78864682  0.58117068  0.52698869]\n",
      " [ 0.12746073  0.57632226  0.7341361   0.40259528  0.4287056   0.65959179\n",
      "   0.15043941  0.31832516  0.43690103  0.18125151  0.38751271  0.717085\n",
      "   0.80123001  0.73989534  0.50207788  0.4642967 ]\n",
      " [ 0.13945937  0.55163407  0.7223177   0.41603133  0.44143528  0.66948217\n",
      "   0.15613405  0.33669403  0.43700132  0.18105952  0.3861483   0.70811087\n",
      "   0.79458827  0.72580874  0.49339053  0.44845974]\n",
      " [ 0.13654141  0.48674026  0.80694008  0.30669942  0.56263697  0.65702188\n",
      "   0.1532962   0.40506229  0.53345579  0.1348618   0.37143165  0.71475589\n",
      "   0.78726411  0.70103151  0.52853388  0.38627633]\n",
      " [ 0.13166356  0.55130708  0.75171822  0.40902984  0.45188832  0.6567297\n",
      "   0.15456353  0.31604448  0.44324529  0.17099875  0.38202119  0.69221586\n",
      "   0.78805459  0.74973863  0.50217563  0.46639466]\n",
      " [ 0.17191656  0.56666446  0.76289117  0.33790958  0.57055444  0.66204184\n",
      "   0.16484019  0.35837135  0.42414922  0.21562377  0.32464689  0.76766944\n",
      "   0.80519629  0.74734473  0.57357621  0.56227982]\n",
      " [ 0.14956163  0.52249789  0.84678692  0.22361328  0.66431755  0.65289211\n",
      "   0.15116327  0.40908679  0.51506007  0.15196115  0.30279168  0.78318781\n",
      "   0.8053413   0.74328947  0.61467046  0.51279181]]\n",
      "\n",
      "Probabilities: \n",
      " [ 0.5623672   0.82815796  0.79375088  0.78649455  0.79683888  0.79787099\n",
      "  0.82452643  0.84132642]\n",
      "\n",
      "Prediction  : [1 1 1 1 1 1 1 1]\n",
      "Absolute error :  4.29662257433\n",
      "X-entropy loss :  7.8703\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Try out the example\n",
    "# 00001001 + 00111100 = 01000101\n",
    "#    9     +    60    = 69\n",
    "x = np.array([\n",
    "    # t=0   t=1    t=2    t=3    t=4    t=5    t=6   t=7\n",
    "    [0,0], [0,0], [0,1], [0,1], [1,1], [0,1], [0,0], [1,0]\n",
    "]).reshape([1,8,2])\n",
    "y = np.array([0, 1, 0, 0, 0, 1, 0, 1]).reshape([1,8])\n",
    "    \n",
    "# train\n",
    "sess.run(train_step, {X: x, Y: y})\n",
    "    \n",
    "# print result\n",
    "[output_vals, _probs, _loss] = sess.run([values, h, loss], {X: x, Y: y})\n",
    "print('Raw output values:')\n",
    "print(output_vals)\n",
    "\n",
    "# prediction\n",
    "probs = np.array(_probs).reshape([8])\n",
    "prediction = np.array([1 if p >= 0.5 else 0 for p in probs]).reshape([8])\n",
    "print()\n",
    "print('Probabilities: \\n', probs)\n",
    "print()\n",
    "print('Prediction  :', prediction)\n",
    "\n",
    "# calculate absolute error\n",
    "error = np.sum(np.absolute(y - probs))\n",
    "\n",
    "# print out pre-training X-entropy loss and absolute error\n",
    "print('Absolute error : ', error)\n",
    "print('X-entropy loss : ', _loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1         :  [0 0 1 0 1 1 0 1]  ( 45 )\n",
      "Input 2         :  [0 0 0 1 1 0 1 0]  ( 26 )\n",
      "True            :  [0 1 0 0 0 1 1 1]  ( 71 )\n",
      "Predicted       :  [0 0 1 1 0 1 1 1]  ( 55 )\n",
      "Absolute error  :  3.73035\n",
      "X-entropy loss  :  5.47834\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 0 0 0 1 1 1 0]  ( 14 )\n",
      "Input 2         :  [0 0 1 1 0 1 0 1]  ( 53 )\n",
      "True            :  [0 1 0 0 0 0 1 1]  ( 67 )\n",
      "Predicted       :  [1 0 1 1 1 0 1 1]  ( 187 )\n",
      "Absolute error  :  4.29031\n",
      "X-entropy loss  :  6.66568\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 0 1 0 0 0 0 1]  ( 33 )\n",
      "Input 2         :  [0 1 0 1 1 1 1 0]  ( 94 )\n",
      "True            :  [0 1 1 1 1 1 1 1]  ( 127 )\n",
      "Predicted       :  [1 1 1 1 1 1 1 1]  ( 255 )\n",
      "Absolute error  :  2.57187\n",
      "X-entropy loss  :  3.17627\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 0 1 1 0 0 1 0]  ( 50 )\n",
      "Input 2         :  [0 0 0 0 0 0 1 1]  ( 3 )\n",
      "True            :  [0 0 1 1 0 1 0 1]  ( 53 )\n",
      "Predicted       :  [1 0 1 1 0 0 0 1]  ( 177 )\n",
      "Absolute error  :  3.221\n",
      "X-entropy loss  :  4.36655\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 1 1 1 1 1 1 1]  ( 127 )\n",
      "Input 2         :  [0 1 0 1 1 0 1 0]  ( 90 )\n",
      "True            :  [1 1 0 1 1 0 0 1]  ( 217 )\n",
      "Predicted       :  [1 0 1 0 0 1 0 1]  ( 165 )\n",
      "Absolute error  :  4.30266\n",
      "X-entropy loss  :  6.77041\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 1 1 1 1 0 0 1]  ( 121 )\n",
      "Input 2         :  [0 1 1 0 1 0 0 0]  ( 104 )\n",
      "True            :  [1 1 1 0 0 0 0 1]  ( 225 )\n",
      "Predicted       :  [1 0 0 1 0 0 0 1]  ( 145 )\n",
      "Absolute error  :  3.78583\n",
      "X-entropy loss  :  5.52448\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 0 0 0 0 0 1 1]  ( 3 )\n",
      "Input 2         :  [0 1 0 1 1 1 1 1]  ( 95 )\n",
      "True            :  [0 1 1 0 0 0 1 0]  ( 98 )\n",
      "Predicted       :  [1 0 0 1 1 1 0 0]  ( 156 )\n",
      "Absolute error  :  4.98435\n",
      "X-entropy loss  :  8.13293\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 1 0 0 1 0 1 0]  ( 74 )\n",
      "Input 2         :  [0 1 1 0 1 1 0 1]  ( 109 )\n",
      "True            :  [1 0 1 1 0 1 1 1]  ( 183 )\n",
      "Predicted       :  [1 0 1 0 0 1 1 1]  ( 167 )\n",
      "Absolute error  :  2.79596\n",
      "X-entropy loss  :  3.56718\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 0 1 0 1 1 0 0]  ( 44 )\n",
      "Input 2         :  [0 0 1 1 1 0 1 1]  ( 59 )\n",
      "True            :  [0 1 1 0 0 1 1 1]  ( 103 )\n",
      "Predicted       :  [1 0 0 1 0 1 1 1]  ( 151 )\n",
      "Absolute error  :  3.66828\n",
      "X-entropy loss  :  5.39607\n",
      "---------------------------------\n",
      "\n",
      "Input 1         :  [0 0 0 1 1 0 1 0]  ( 26 )\n",
      "Input 2         :  [0 1 0 0 0 1 0 0]  ( 68 )\n",
      "True            :  [0 1 0 1 1 1 1 0]  ( 94 )\n",
      "Predicted       :  [1 0 0 1 1 1 1 0]  ( 158 )\n",
      "Absolute error  :  3.09235\n",
      "X-entropy loss  :  4.10179\n",
      "---------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's train\n",
    "\n",
    "# generate the training data set\n",
    "binary_dim = 8\n",
    "largest_number = pow(2, binary_dim)\n",
    "a_list = []\n",
    "b_list = []\n",
    "n_examples = 1000\n",
    "for j in range(n_examples):\n",
    "    a_list.append(np.random.randint(largest_number/2))\n",
    "    b_list.append(np.random.randint(largest_number/2))\n",
    "\n",
    "# train\n",
    "n_epochs = 10\n",
    "for i in range(n_epochs):\n",
    "    \n",
    "    for j in range(n_examples):\n",
    "        a_int = a_list[j]\n",
    "        b_int = b_list[j]\n",
    "        c_int = a_int + b_int\n",
    "        a = np.unpackbits(np.array([a_int], dtype=np.uint8))\n",
    "        b = np.unpackbits(np.array([b_int], dtype=np.uint8))\n",
    "        c = np.unpackbits(np.array([c_int], dtype=np.uint8))\n",
    "        ab = np.c_[a,b]\n",
    "        x = np.array(ab).reshape([1,binary_dim,2])\n",
    "        y = np.array(c).reshape([1,binary_dim])\n",
    "        sess.run(train_step, {X: x, Y: y})\n",
    "        \n",
    "    # print out loss for a random example\n",
    "    if (i%1 == 0):\n",
    "        # pick a random example out of the training data set\n",
    "        k = np.random.randint(n_examples)\n",
    "        a_int = a_list[k]\n",
    "        b_int = b_list[k]\n",
    "        c_int = a_int + b_int\n",
    "        a = np.unpackbits(np.array([a_int], dtype=np.uint8))\n",
    "        b = np.unpackbits(np.array([b_int], dtype=np.uint8))\n",
    "        c = np.unpackbits(np.array([c_int], dtype=np.uint8))\n",
    "        ab = np.c_[a,b]\n",
    "        x = np.array(ab).reshape([1,binary_dim,2])\n",
    "        y = np.array(c).reshape([1,binary_dim])\n",
    "        \n",
    "        # get predicted value\n",
    "        [_probs, _loss] = sess.run([h, loss], {X: x, Y: y})\n",
    "        probs = np.array(_probs).reshape([8])\n",
    "        prediction = np.array([1 if p >= 0.5 else 0 for p in probs]).reshape([8])\n",
    "        pred_int = np.sum(np.packbits(prediction))\n",
    "        \n",
    "        # calculate error\n",
    "        error = np.sum(np.absolute(y - probs))\n",
    "\n",
    "        print('Input 1         : ', a, ' (', a_int, ')')\n",
    "        print('Input 2         : ', b, ' (', b_int, ')')\n",
    "        print('True            : ', c, ' (', c_int, ')')\n",
    "        print('Predicted       : ', prediction, ' (', pred_int, ')')\n",
    "        print('Absolute error  : ', error)\n",
    "        print('X-entropy loss  : ', _loss)\n",
    "        print('---------------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
